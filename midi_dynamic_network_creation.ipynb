{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "### \\\\\\ --- This script wrangles MIDI data into a format usable by R Studio for the purpose of plotting dynamic networks. --- /// ###\n",
    "# Python version: Targets 3.6.6\n",
    "# Libraries: csv, itertools, mido\n",
    "# Written by: Kyle Quarles\n",
    "\n",
    "import csv\n",
    "import itertools\n",
    "from mido import MidiFile #! Targets no later than Python 3.6!\n",
    "mid = MidiFile('ockIntroitus.mid')\n",
    "\n",
    "###Getting oriented with Mido:\n",
    "\n",
    "# how to print just midi data;;; \n",
    "#for i, track in enumerate(mid.tracks):\n",
    "    #print('Track {}: {}'.format(i, track.name))#be advised that in MIDI format a note_on messsage with a velocity of 0 is equivalent to a note_off message\n",
    "    #for msg in track:\n",
    "        #print(str(msg))\n",
    "\n",
    "#how to see how many tracks in a MidiFile\n",
    "#mid.print_tracks(meta_only=True)\n",
    "\n",
    "### \\\\\\ --- Dynamic NODE creation from a midi file --- /// ###\n",
    "\n",
    "mid = MidiFile('ockIntroitus.mid')#replace this with whatever .mid file you want to analyze (make sure it's in same directory as this script)\n",
    "\n",
    "def midi2list(midi_file): # gets only the note_on and note_off messages, creates a sublist for each, and breaks their parameters into separate strings\n",
    "    for i, track in enumerate(midi_file.tracks):\n",
    "        extraction = [ list(str(msg).split(\" \")) for msg in track if msg.type == 'note_on' or msg.type == 'note_off' ]\n",
    "        yield [ 'Track {} {}'.format(i, track.name), list(extraction) ]\n",
    "\n",
    "def get_full(some_list): # filters out empty message lists (usually the meta message list is stored in track 0, so it's empty from the midi2list function filtering only note_on/note_off messages)\n",
    "    return [ i for i in some_list if len(i[1]) != 0]\n",
    "\n",
    "def numberer(message_list): # adds number to beginning of each sub-list, which will be used in .csv creation to indicate row number (turns out this is not needed, I misunderstood how csv writer worked...)\n",
    "    for entry in message_list:\n",
    "        counter = 1\n",
    "        for message in entry[1]:\n",
    "            message.insert(0, counter)\n",
    "            counter += 1\n",
    "    return message_list\n",
    "\n",
    "def standardizer(numbed_list): # tests for note_on messages with velocity = 0; changes them to note_offs\n",
    "    for entry in numbed_list:\n",
    "        for message in entry[1]:\n",
    "            if message[4] == 'velocity=0':\n",
    "                 message[1] = 'note_off'\n",
    "    return numbed_list\n",
    "\n",
    "def abs_onsets(pl): # MIDI protocol lists times as 'time from last event' in other words delta times; this gets just the onset delta-times and converts them to an int list of absolute times\n",
    "    for entry in pl:\n",
    "        deltas = [ int( message[5].partition('=')[2]) for message in entry[1] ]\n",
    "        yield itertools.accumulate(deltas)\n",
    "\n",
    "def lister(blah): # this is just dealing with the yield iterator\n",
    "    return [ list(item) for item in blah  ]\n",
    "\n",
    "def final_formatter(combined_func, onsets): # finally putting everything together\n",
    "    for i, entry in enumerate(combined_func):\n",
    "        for j in range(0,len(entry[1]), 2): #we want to step through 'combined_func' by twos, to get the start and end time of a single node from a note_on message and the note_off immediately following\n",
    "            onset = onsets[i][j]\n",
    "            terminus = onsets[i][j+1]\n",
    "            vertex_id = combined_func[i][1][j][3].partition('=')[2]\n",
    "            onset_censored = 'FALSE'\n",
    "            terminus_censored = 'FALSE'\n",
    "            duration = terminus - onset\n",
    "            yield [ onset, terminus, vertex_id, onset_censored, terminus_censored, duration ]\n",
    "\n",
    "def csv_dynamic_node_maker(partitioned_list): # DEPRECATED, see new csv creators at bottom;making a .csv file out of each track's messages in 'partitioned_list' and saving it\n",
    "    for i, entry in enumerate(partitioned_list):\n",
    "        entry = [['onset', 'terminus', 'vertex.id', 'onset.censored', 'terminus.censored', 'duration']] + entry # column header labels\n",
    "        title = i + 1 # titling each .csv file by its track's index ( we filtered out MetaMessage track 0, so need to add 1 to index to accurately reflect original track number)\n",
    "        with open('track_{}_dynamic_nodes.csv'.format(title), 'w', newline='') as file:\n",
    "            writer = csv.writer(file)\n",
    "            writer.writerows(entry)\n",
    "\n",
    "raw_midi_list = list(midi2list(mid))\n",
    "# print('raw_midi_list',raw_midi_list)\n",
    "full_messages = get_full(raw_midi_list)\n",
    "# print('full_messages',full_messages)\n",
    "numbed_full_mess = numberer(full_messages)\n",
    "# print('numbed_full_mess',numbed_full_mess)\n",
    "standardized = standardizer(numbed_full_mess)\n",
    "# print('standardized',standardized)\n",
    "combined_func = standardizer(numberer(get_full(list(midi2list(mid)))))\n",
    "# print('combined_func',combined_func)\n",
    "onsetz = list(abs_onsets(combined_func))\n",
    "list_onsetz = lister(onsetz)\n",
    "# print('list_onsetz',list_onsetz)\n",
    "node_partition_sizes = [len(entry[1]) // 2 for entry in combined_func] # but the yield doesn't distinguish between tracks, so we have to make this list for how many messages each track contains\n",
    "# print('node_partition_sizes',node_partition_sizes)\n",
    "final_format = final_formatter(combined_func, list_onsetz)\n",
    "# print('final_format',list(final_format))\n",
    "partitioned_list = [list(itertools.islice(final_format, elem)) for elem in node_partition_sizes] #islice takes a generator for its first argument! i.e. the yield from 'final_formatter'. And we use 'node_partition_sizes' to tell islice how to group messages from the yield generator.\n",
    "#print('partitioned_list',partitioned_list)\n",
    "\n",
    "#csv_dynamic_node_maker(partitioned_list) # DEPRECATED; these are the dynamic node lists used in R; saved to same directory this script is in\n",
    "# Uses the midi keys names for note id numbering;\n",
    "# that can cause problems in various R packages who think that if they see a vertex.id of n, then they need to automatically create >=n nodes.\n",
    "#kept for posterity because we may need this form for some purposes, but for the R script as currently configured it's non-functional.\n",
    "\n",
    "\n",
    "### \\\\\\ --- Dynamic EDGE creation from Dynamic nodes --- /// ###\n",
    "\n",
    "def edge_converter(partitioned_list):\n",
    "    for track in partitioned_list:\n",
    "        for j in range(len(track) - 1): #we need to stop this iterative process before we reach the last message so that j doesn't go out of range\n",
    "            onset = track[j][1]\n",
    "            terminus = track[j+1][1]\n",
    "            tail = track[j][2]\n",
    "            head = track[j+1][2]\n",
    "            onset_censored = 'FALSE'\n",
    "            terminus_censored = 'FALSE'\n",
    "            duration = terminus - onset\n",
    "            edge_id = tail + head\n",
    "            yield [onset, terminus, tail, head, onset_censored, terminus_censored, duration, edge_id ]\n",
    "\n",
    "def edge_id_maker(partitioned_edge_conversion): #generates a list of unordered sets containing the unique node_pair strings for each track\n",
    "    for track in partitioned_edge_conversion:\n",
    "        node_pair_set = set()\n",
    "        for msg in track:\n",
    "            node_pair_set.add(msg[7])\n",
    "        yield node_pair_set\n",
    "\n",
    "def edge_id_dict_maker(edge_list): # list of dictionaries containing node_pair strings as keys and ints as values\n",
    "    return [{key:count for count, key in enumerate(edge, 1)} for edge in edge_list]\n",
    "\n",
    "def edge_id_converter(partitioned_edge_conversion, edge_id_dict_list): # replacing each unique node_pair string with its dict value (per track)\n",
    "    dummy = partitioned_edge_conversion.copy()\n",
    "    for i, track in enumerate(dummy):\n",
    "        for msg in track:\n",
    "            msg.append(edge_id_dict_list[i][msg[7]])\n",
    "            msg.pop(7)\n",
    "    return dummy\n",
    "\n",
    "def csv_dynamic_edge_maker(edge_id_conversion): #DEPRECATED; see new csv creators below\n",
    "    for i, entry in enumerate(edge_id_conversion):\n",
    "        entry = [['onset', 'terminus', 'tail', 'head', 'onset.censored', 'terminus.censored', 'duration', 'edge.id']] + entry # column header labels\n",
    "        title = i + 1 # titling each .csv file by its index ( we filtered out MetaMessage track 0, so need to add 1 to index to accurately reflect original track number)\n",
    "        with open('track_{}_dynamic_edges.csv'.format(title), 'w', newline='') as file:\n",
    "            writer = csv.writer(file)\n",
    "            writer.writerows(entry)\n",
    "\n",
    "def static_edge_maker_conversion(edge_id_conversion): # getting only the tail and head info from the dynamic edge list\n",
    "    for track in edge_id_conversion:\n",
    "        yield [[msg[2], msg[3], '1'] for msg in track ] #1 is for adding weight; useful for summing total arrows in R to give aggregate weights\n",
    "\n",
    "def csv_static_edge_maker(static_edge_list):\n",
    "    for i, entry in enumerate(static_edge_list):\n",
    "        entry = [['tail', 'head', 'weight']] + entry #column header labels\n",
    "        title = i + 1 # titling each .csv file by its index ( we filtered out MetaMessage track 0, so need to add 1 to index to accurately reflect original track number)\n",
    "        with open('track_{}_static_edges.csv'.format(title), 'w', newline='') as file:\n",
    "            writer = csv.writer(file)\n",
    "            writer.writerows(entry)\n",
    "            #print(entry)\n",
    "\n",
    "edge_conversion = edge_converter(partitioned_list)\n",
    "# print('edge_conversion',list(edge_conversion))\n",
    "edge_partition_sizes = [i-1 for i in node_partition_sizes]# num(edges) is always num(nodes) - 1, in each track\n",
    "# print(edge_partition_sizes)\n",
    "partitioned_edge_conversion = [list(itertools.islice(edge_conversion, elem)) for elem in edge_partition_sizes] # like before the yield generator needs to be told how to group results into tracks\n",
    "# print(partitioned_edge_conversion)\n",
    "edge_list = list(edge_id_maker(partitioned_edge_conversion)) # this is a list of lists of strings (for each track) of the form ''tail'+'head'', i.e. '7172' or '26127' etc.; we assign a unique int to each unique string in the next step\n",
    "#print(edge_list)\n",
    "edge_id_dict_list = edge_id_dict_maker(edge_list)\n",
    "#print(edge_id_dict_list)\n",
    "edge_id_conversion = edge_id_converter(partitioned_edge_conversion, edge_id_dict_list)\n",
    "# print('edge_id_conversion',edge_id_conversion)\n",
    "\n",
    "\n",
    "#csv_dynamic_edge_maker(edge_id_conversion) # DEPRECATED, see below these are the dynamic edge lists, output and saved\n",
    "static_edge_list = list(static_edge_maker_conversion(edge_id_conversion))\n",
    "#print('static_edge_list',static_edge_list)\n",
    "# csv_static_edge_maker(static_edge_list) #DEPRECATED;# Uses the midi keys names for note id numbering;\n",
    "# that can cause problems in various R packages who think that if they see a vertex.id of n, then they need to automatically create >=n nodes.\n",
    "#kept for posterity because we may need this form for some purposes, but for the R script as currently configured it's non-functional. \n",
    "\n",
    "### \\\\\\ --- Vertex attributes sub-routine --- /// ###\n",
    "# two ways to do this\n",
    "\n",
    "chromatic_pitches = ['C','C#','D','D#','E','F','F#','G','G#','A','A#','B']\n",
    "\n",
    "def MIDI_pitch_mapping(chromatic_pitches):\n",
    "    i = 0\n",
    "    for j in range(24,128):\n",
    "        note = chromatic_pitches[(j-24) % 12]\n",
    "        if note == 'C':\n",
    "            i += 1\n",
    "        yield [ j, note + str(i) ]\n",
    "\n",
    "shame = [[21, 'A0'], [22, 'A#0'], [23, 'B0']] #lol ugly hack, hence 'shame'\n",
    "\n",
    "def csv_total_vertex_attributes_maker(MIDI_map): # first way is to include every possible MIDI note name in the vertex attributes file\n",
    "    alias = MIDI_map[:]\n",
    "    alias.insert(0, ['vertex.id', 'note_name',]) # column header labels\n",
    "    with open('MIDI_map.csv', 'w', newline='') as file: \n",
    "        writer = csv.writer(file)\n",
    "        writer.writerows(alias)\n",
    "\n",
    "### Second Way ###\n",
    "def get_node_sets(partitioned_list): # getting an unordered set of nodes present in each track; we will need this if we want to send a vertexAttributes file to R with ONLY those notes used in a track as vertices, instead of full MIDI_map\n",
    "    for track in partitioned_list:\n",
    "        node_set = set()\n",
    "        for msg in track:\n",
    "            node_set.add(int(msg[2]))\n",
    "        yield node_set\n",
    "\n",
    "def node_filter(MIDI_map): #structures node_list with midi_key and note_name string, to be used in .csv creator\n",
    "            return [ list(filter(lambda m: m[0] in node_list, MIDI_map)) for node_list in node_lists ] # filter generators have no intrinsic type so type needs to be specificied by running list() inside comprehension\n",
    "\n",
    "def number_from_1(filt_list):\n",
    "    for track in (filt_list):\n",
    "        for countish, msg in enumerate(track):\n",
    "             yield [ countish + 1, msg[1] ]\n",
    "\n",
    "def csv_vertex_attr_by_track(grouping_proper_numbered):#DEPRECATED, see below for new csv creators\n",
    "    for i, entry in enumerate(grouping_proper_numbered):\n",
    "        entry = [['vertex.id', 'name']] + entry #column header labels\n",
    "        title = i + 1 # titling each .csv file by its index ( we filtered out MetaMessage track 0, so need to add 1 to index to accurately reflect original track number)\n",
    "        with open('track_{}_static_nodes.csv'.format(title), 'w', newline='') as file:\n",
    "            writer = csv.writer(file)\n",
    "            writer.writerows(entry)\n",
    "\n",
    "MIDI_map = shame + list(MIDI_pitch_mapping(chromatic_pitches))\n",
    "#print('MIDI_map',MIDI_map)\n",
    "csv_total_vertex_attributes_maker(MIDI_map) # output and saved; this should be sent to R SNA package as vertex attributes, aka vertex.attr\n",
    "node_sets = list(get_node_sets(partitioned_list))\n",
    "#print('node_sets',node_sets)\n",
    "node_lists = [ sorted(list(node_set)) for node_set in node_sets ] #ordering each set\n",
    "#print('node_lists',node_lists)\n",
    "node_list_partition_sizes = [ len(track) for track in node_lists ] #same method from before; we're going to need this for our number_from_1 function to tell yield how to group tracks using islice\n",
    "#print('node_list_partition_sizes',node_list_partition_sizes)\n",
    "formatted_node_lists = node_filter(MIDI_map)\n",
    "#print('formatted_node_lists',list(formatted_node_lists))\n",
    "proper_numbered = number_from_1(formatted_node_lists)\n",
    "grouping_proper_numbered = [list(itertools.islice(proper_numbered, elem)) for elem in node_list_partition_sizes]\n",
    "#print('grouping_proper_numbered',grouping_proper_numbered)\n",
    "\n",
    "#csv_vertex_attr_by_track(grouping_proper_numbered)#DEPRECATED;# Uses the midi keys names for note id numbering;\n",
    "# that can cause problems in various R packages who think that if they see a vertex.id of n, then they need to automatically create >=n nodes.\n",
    "#kept for posterity because we may need this form for some purposes, but for the R script as currently configured it's non-functional. \n",
    "\n",
    "### \\\\\\ --- Various hacks to fix issue of R assuming I want all nodes drawn up to a certain vertex.id; --- /// ###\n",
    "#  so if I just use MIDI numbers as vertex ids, then if the highest midi number used is, for example say, 72, then it will draw 72 nodes, even if vertex.ids 1-60 are never used.\n",
    "# so below we are, ex-post-facto, numbering each midi_note with a unique smaller number, per track (because the notes used per track change)\n",
    "\n",
    "low_number_lists=[]\n",
    "for track in grouping_proper_numbered:\n",
    "    new_track=[]\n",
    "    for msg in track:\n",
    "        new_track.append(msg[0])\n",
    "    low_number_lists.append(new_track)\n",
    "#print('low_number_lists',low_number_lists)\n",
    "\n",
    "midi_key_number_lists=[]\n",
    "for track in formatted_node_lists:\n",
    "    new_track=[]\n",
    "    for msg in track:\n",
    "        new_track.append(msg[0])\n",
    "    midi_key_number_lists.append(new_track)\n",
    "#print('midi_key_number_lists',midi_key_number_lists)\n",
    "\n",
    "node_id_dict=[]\n",
    "for i in range(len(low_number_lists)):\n",
    "    node_id_dict.append(dict(list(zip(midi_key_number_lists[i],low_number_lists[i]))))\n",
    "#print('node_id_dict',node_id_dict)\n",
    "\n",
    "corrected_static_edges=[]\n",
    "for i, track in enumerate(static_edge_list):\n",
    "    new_track=[]\n",
    "    for msg in track:\n",
    "        new_track.append([node_id_dict[i][int(msg[0])],node_id_dict[i][int(msg[1])],msg[2]])\n",
    "    corrected_static_edges.append(new_track)\n",
    "#print('corrected_static_edges',corrected_static_edges)\n",
    "csv_static_edge_maker(corrected_static_edges)\n",
    "\n",
    "corrected_dynamic_edges=[]\n",
    "for i, track in enumerate(edge_id_conversion):\n",
    "    new_track=[]\n",
    "    for msg in track:\n",
    "        new_track.append([msg[0],msg[1],node_id_dict[i][int(msg[2])],node_id_dict[i][int(msg[3])],msg[4],msg[5],msg[6],msg[7]])\n",
    "    corrected_dynamic_edges.append(new_track)\n",
    "#print('corrected_dynamic_edges',corrected_dynamic_edges)\n",
    "csv_dynamic_edge_maker(corrected_dynamic_edges)\n",
    "\n",
    "corrected_dynamic_nodes=[]\n",
    "for i, track in enumerate(partitioned_list):\n",
    "    new_track=[]\n",
    "    for msg in track:\n",
    "        new_track.append([msg[0],msg[1],node_id_dict[i][int(msg[2])],msg[3],msg[4],msg[5]])\n",
    "    corrected_dynamic_nodes.append(new_track)\n",
    "#print('corrected_dynamic_nodes',corrected_dynamic_nodes)\n",
    "csv_dynamic_node_maker(corrected_dynamic_nodes)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "f4e9cda46bb2d9d7fe6ecdff0f8336a934348bf06cb492f2f42f60739b3403b4"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
