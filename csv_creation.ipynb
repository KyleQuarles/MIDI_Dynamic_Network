{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 48,
   "source": [
    "###basic csv file creation\r\n",
    "import csv\r\n",
    "\r\n",
    "with open('persons.csv', 'w', newline='') as file:\r\n",
    "    writer = csv.writer(file)\r\n",
    "    writer.writerow(['Name', 'Profession'])\r\n",
    "    writer.writerow(['Derek', 'Software Developer'])\r\n",
    "    writer.writerow(['Steve', 'Software Developer'])\r\n",
    "    writer.writerow(['Paul', 'Manager'])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "source": [
    "### writing multiple rows from a python list\r\n",
    "import csv\r\n",
    "row_list = [[\"SN\", \"Name\", \"Contribution\"],\r\n",
    "            [1, \"Linus Torvalds\", \"Linux Kernel\"],\r\n",
    "            [2, \"Tim Berners-Lee\", \"World Wide Web\"],\r\n",
    "            [3, \"Guido van Rossum\", \"Python Programming\"]]\r\n",
    "with open('protagonist.csv', 'w', newline='') as file:\r\n",
    "    writer = csv.writer(file)\r\n",
    "    writer.writerows(row_list)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "### importing midi\r\n",
    "import mido ###why doesn't this effing work?\r\n",
    "from mido import MidiFile\r\n",
    "mid = MidiFile('test1.mid')\r\n",
    "\r\n",
    "### printing midi data;;; be advised that in MIDI format a note_on messsage with a velocity of 0 is equivalent to a note_off message\r\n",
    "for i, track in enumerate(mid.tracks):\r\n",
    "    print('Track {}: {}'.format(i, track.name))\r\n",
    "    for msg in track:\r\n",
    "        print(str(msg))\r\n",
    "\r\n",
    "#how to see how many tracks in a MidiFile\r\n",
    "mid.print_tracks(meta_only=True)\r\n",
    "\r\n",
    "# mido.ticks2second(3840,mid.ticks_per_beat,)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "source": [
    "### Getting only note_on messages\r\n",
    "from mido import MidiFile\r\n",
    "mid = MidiFile('ockIntroitus.mid')\r\n",
    "\r\n",
    "def test(example):\r\n",
    "    for i, track in enumerate(example.tracks):\r\n",
    "        print('Track {}: {}'.format(i, track.name))\r\n",
    "        for msg in track:\r\n",
    "            if msg.type == 'note_on':\r\n",
    "                if msg.velocity == 0:\r\n",
    "                    print('note_off ' + str(msg)[8:]) # this is for MIDI tracks that implement note_offs as zero velocity note_ons ; standardizes to using note_offs\r\n",
    "                else: print(str(msg))\r\n",
    "\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "source": [
    "### \\\\\\ --- tools to generate DynamicNodeList from a midi file --- /// ###\r\n",
    "\r\n",
    "from mido import MidiFile\r\n",
    "import itertools\r\n",
    "import csv\r\n",
    "mid = MidiFile('test1.mid')\r\n",
    "\r\n",
    "def midi2list(midi_file): # gets only the note_on and note_off messages, creates a sublist for each, and breaks their parameters into separate strings\r\n",
    "    for i, track in enumerate(midi_file.tracks):\r\n",
    "        extraction = [ list(str(msg).split(\" \")) for msg in track if msg.type == 'note_on' or msg.type == 'note_off' ]\r\n",
    "        yield [ 'Track {} {}'.format(i, track.name), list(extraction) ]\r\n",
    "\r\n",
    "step1 = list(midi2list(mid))\r\n",
    "#print(step1)\r\n",
    "\r\n",
    "def get_full(something): # filters out empty message lists (usually the meta message list is stored in track 0, so it's empty from the midi2list function filtering only note_on/note_off messages)\r\n",
    "    return [ i for i in something if len(i[1]) != 0]\r\n",
    "\r\n",
    "step2 = get_full(step1)\r\n",
    "# print(step2)\r\n",
    "\r\n",
    "def numberer(message_list): # adds number to beginning of each sub-list, which will be used in .csv creation to indicate row number (turns out this is not needed, I misunderstood how csv writer worked...)\r\n",
    "    for entry in message_list:\r\n",
    "        counter = 1\r\n",
    "        for message in entry[1]:\r\n",
    "            message.insert(0, counter)\r\n",
    "            counter += 1\r\n",
    "    return message_list\r\n",
    "\r\n",
    "step3 = numberer(step2)\r\n",
    "# print(step3)\r\n",
    "\r\n",
    "def standardizer(numbed_list): # tests for note_on messages with velocity = 0; changes them to note_offs\r\n",
    "    for entry in numbed_list:\r\n",
    "        for message in entry[1]:\r\n",
    "            if message[4] == 'velocity=0':\r\n",
    "                 message[1] = 'note_off'\r\n",
    "    return numbed_list\r\n",
    "\r\n",
    "step4 = standardizer(step3)\r\n",
    "# print(step4)\r\n",
    "\r\n",
    "combined_func = standardizer(numberer(get_full(list(midi2list(mid)))))\r\n",
    "# print(combined_func)\r\n",
    "\r\n",
    "def abs_onsets(pl): # gets just the onset delta-times and converts them to an int list of absolute times\r\n",
    "    for entry in pl:\r\n",
    "        deltas = [ int( message[5].partition('=')[2]) for message in entry[1] ]\r\n",
    "        yield itertools.accumulate(deltas)\r\n",
    "\r\n",
    "onsetz = list(abs_onsets(combined_func))\r\n",
    "\r\n",
    "def lister(blah): # this is just dealing with the yield iterator\r\n",
    "    return [ list(item) for item in blah  ]\r\n",
    "\r\n",
    "list_onsetz = lister(onsetz)\r\n",
    "# print(list_onsetz)\r\n",
    "\r\n",
    "def final_format(combined_func, onsets): # finally putting everything together\r\n",
    "    for i, entry in enumerate(combined_func):\r\n",
    "        for j in range(0,len(entry[1]), 2): #we want to step through 'combined_func' by twos, to get the start and end time of a single node from a note_on message and the note_off immediately following\r\n",
    "            yield [ onsets[i][j], onsets[i][j+1], combined_func[i][1][j][3].partition('=')[2], 'FALSE', 'FALSE',  onsets[i][j+1] - onsets[i][j] ]\r\n",
    "\r\n",
    "node_partition_sizes = [len(entry[1]) // 2 for entry in combined_func] # but the yield doesn't distinguish between tracks, so we have to make this list for how many messages each track contains\r\n",
    "# print(node_partition_sizes)\r\n",
    "\r\n",
    "ff = final_format(combined_func, list_onsetz)\r\n",
    "# print(list(ff))\r\n",
    "\r\n",
    "partitioned_list = [list(itertools.islice(ff, elem)) for elem in node_partition_sizes] #islice takes a generator for its first argument! i.e. the yield from 'final_format'. And we use 'node_partition_sizes' to tell islice how to group messages from the yield generator.\r\n",
    "# print(partitioned_list)\r\n",
    "\r\n",
    "def csv_dynamic_node_maker(partitioned_list): #making a .csv file out of each track's messages in 'partitioned_list' and saving it\r\n",
    "    for i, entry in enumerate(partitioned_list):\r\n",
    "        entry = [['onset', 'terminus', 'vertex.id', 'onset.censored', 'terminus.censored', 'duration']] + entry # column header labels\r\n",
    "        title = i + 1 # titling each .csv file by its track's index ( we filtered out MetaMessage track 0, so need to add 1 to index to accurately reflect original track number)\r\n",
    "        with open('track_{}_dynamic_nodes.csv'.format(title), 'w', newline='') as file:\r\n",
    "            writer = csv.writer(file)\r\n",
    "            writer.writerows(entry)\r\n",
    "\r\n",
    "csv_dynamic_node_maker(partitioned_list)\r\n",
    "\r\n",
    "def edge_converter(partitioned_list):\r\n",
    "    for track in partitioned_list:\r\n",
    "        for j in range(len(track) - 1): #we need to stop this iterative process before we reach the last message so that j doesn't go out of range\r\n",
    "            tail = track[j][2]\r\n",
    "            head = track[j+1][2]\r\n",
    "            onset = track[j+1][0]\r\n",
    "            terminus = track[j+1][1]\r\n",
    "            duration = terminus - onset\r\n",
    "            edge_id = tail + head\r\n",
    "            yield [onset, terminus, tail, head, 'FALSE', 'FALSE', duration, edge_id ]\r\n",
    "\r\n",
    "edge_conversion = edge_converter(partitioned_list)\r\n",
    "# print(list(edge_conversion))\r\n",
    "\r\n",
    "edge_partition_sizes = [i-1 for i in node_partition_sizes]# num(edges) is always num(nodes) - 1, in each track;\r\n",
    "# print(edge_partition_sizes)\r\n",
    "\r\n",
    "partitioned_edge_conversion = [list(itertools.islice(edge_conversion, elem)) for elem in edge_partition_sizes] # like before the yield generator needs to be told how to group results into tracks.\r\n",
    "# print(partitioned_edge_conversion)\r\n",
    "\r\n",
    "def edge_id_maker(partitioned_edge_conversion): #generates a list of unordered sets containing the unique node_pair strings for each track\r\n",
    "    for track in partitioned_edge_conversion:\r\n",
    "        node_pair_set = set()\r\n",
    "        for msg in track:\r\n",
    "            node_pair_set.add(msg[7])\r\n",
    "        yield node_pair_set\r\n",
    "\r\n",
    "edge_list = list(edge_id_maker(partitioned_edge_conversion))\r\n",
    "# print(edge_list)\r\n",
    "\r\n",
    "def edge_id_dict_maker(edge_list): # list of dictionaries containing node_pair strings as keys and ints as values\r\n",
    "    return [{key:count for count, key in enumerate(edge, 1)} for edge in edge_list]\r\n",
    "\r\n",
    "edge_id_dict_list = edge_id_dict_maker(edge_list)\r\n",
    "# print(edge_id_dict_list)\r\n",
    "\r\n",
    "def edge_id_converter(partitioned_edge_conversion, edge_id_dict_list): # replacing each unique node_pair string with its dict value (per track)\r\n",
    "    dummy = partitioned_edge_conversion.copy()\r\n",
    "    for i, track in enumerate(dummy):\r\n",
    "        for msg in track:\r\n",
    "            msg.append(edge_id_dict_list[i][msg[7]])\r\n",
    "            msg.pop(7)\r\n",
    "    return dummy\r\n",
    "\r\n",
    "edge_id_conversion = edge_id_converter(partitioned_edge_conversion, edge_id_dict_list)\r\n",
    "# print(edge_id_conversion)\r\n",
    "\r\n",
    "def csv_dynamic_edge_maker(edge_id_conversion):\r\n",
    "    for i, entry in enumerate(edge_id_conversion):\r\n",
    "        entry = [['onset', 'terminus', 'tail', 'head', 'onset.censored', 'terminus.censored', 'duration', 'edge.id']] + entry # column header labels\r\n",
    "        title = i + 1 # titling each .csv file by its index ( we filtered out MetaMessage track 0, so need to add 1 to index to accurately reflect original track number)\r\n",
    "        with open('track_{}_dynamic_edges.csv'.format(title), 'w', newline='') as file:\r\n",
    "            writer = csv.writer(file)\r\n",
    "            writer.writerows(entry)\r\n",
    "\r\n",
    "csv_dynamic_edge_maker(edge_id_conversion)\r\n",
    "\r\n",
    "def static_edge_maker_conversion(edge_id_conversion): # getting only the tail and head info from the dynamic edge list\r\n",
    "    for track in edge_id_conversion:\r\n",
    "        yield [[msg[2], msg[3]] for msg in track ]\r\n",
    "\r\n",
    "static_edge_list = list(static_edge_maker_conversion(edge_id_conversion))\r\n",
    "# print(static_edge_list)\r\n",
    "\r\n",
    "def csv_static_edge_maker(static_edge_list):\r\n",
    "    for i, entry in enumerate(static_edge_list):\r\n",
    "        entry = [['tail', 'head']] + entry #column header labels\r\n",
    "        title = i + 1 # titling each .csv file by its index ( we filtered out MetaMessage track 0, so need to add 1 to index to accurately reflect original track number)\r\n",
    "        with open('track_{}_static_edges.csv'.format(title), 'w', newline='') as file:\r\n",
    "            writer = csv.writer(file)\r\n",
    "            writer.writerows(entry)\r\n",
    "\r\n",
    "csv_static_edge_maker(static_edge_list)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[[[3840, 7679, '74', '74', 'FALSE', 'FALSE', 3839, 1], [7680, 11519, '74', '74', 'FALSE', 'FALSE', 3839, 1], [11520, 15359, '74', '74', 'FALSE', 'FALSE', 3839, 1]], [[3840, 7679, '71', '72', 'FALSE', 'FALSE', 3839, 2], [7680, 11519, '72', '72', 'FALSE', 'FALSE', 3839, 1], [11520, 15359, '72', '72', 'FALSE', 'FALSE', 3839, 1]], [[3840, 7679, '71', '71', 'FALSE', 'FALSE', 3839, 1], [7680, 11519, '71', '71', 'FALSE', 'FALSE', 3839, 1], [11520, 15359, '71', '71', 'FALSE', 'FALSE', 3839, 1]]]\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "source": [
    "### Creating .csv file for MIDI note names ###\r\n",
    "\r\n",
    "chromatic_pitches = ['C','C#','D','D#','E','F','F#','G','G#','A','A#','B']\r\n",
    "\r\n",
    "def MIDI_pitch_mapping(chromatic_pitches):\r\n",
    "    i = 0\r\n",
    "    for j in range(24,128):\r\n",
    "        note = chromatic_pitches[(j-24) % 12]\r\n",
    "        if note == 'C':\r\n",
    "            i += 1\r\n",
    "        yield [ j, note + str(i) ]\r\n",
    "\r\n",
    "shame = [[21, 'A0'], [22, 'A#0'], [23, 'B0']]\r\n",
    "\r\n",
    "MIDI_map = shame + list(MIDI_pitch_mapping(chromatic_pitches))\r\n",
    "\r\n",
    "def csv_vertex_attributes_maker(MIDI_map):\r\n",
    "    alias = MIDI_map[:]\r\n",
    "    alias.insert(0, ['vertex.id', 'note_name',]) # column header labels\r\n",
    "    with open('MIDI_map.csv', 'w', newline='') as file: \r\n",
    "        writer = csv.writer(file)\r\n",
    "        writer.writerows(alias)\r\n",
    "\r\n",
    "csv_vertex_attributes_maker(MIDI_map)"
   ],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "f7291e4b392a32fbfa525b87d1bbd0a3d888adf3d0deca0c205c61b9e7284b82"
  },
  "kernelspec": {
   "display_name": "Python 3.6.6 64-bit",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": ""
  },
  "orig_nbformat": 2
 },
 "nbformat": 4,
 "nbformat_minor": 2
}